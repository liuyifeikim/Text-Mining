---
title: "R Notebook"
output: html_notebook
---

#Chapter 2

```{r}
library(tidytext)
library(dplyr)
library(tidyr)
library(tidytext)
library(tibble)
library(janeaustenr)
library(stringr)
library(ggplot2)
library(wordcloud)
library(reshape2)
```

```{r}
glimpse(sentiments)
sentiments
```

```{r}
get_sentiments("afinn") #score
get_sentiments("bing")
get_sentiments("nrc")
get_sentiments("loughran")
```

```{r}
count(get_sentiments("nrc"), sentiment, sort = T)
```

```{r}
tidy_books <- austen_books() %>% 
  group_by(book) %>% 
  mutate(linenumber = row_number(), 
         chapter = cumsum(str_detect(text, regex("^CHAPTER \\d+$", ignore_case = T)))) %>% 
  ungroup() %>% 
  unnest_tokens(input = text, output = word)
tidy_books
```

```{r}
nrcjoy <- get_sentiments("nrc") %>% filter(sentiment == "joy")
nrcjoy
```

```{r}
tidy_books %>% 
  filter(book == "Emma") %>% 
  inner_join(nrcjoy) %>% #取交集
  count(word, sort = T)
```

```{r}
js <- tidy_books %>% 
  inner_join(get_sentiments("bing")) %>% #内连接，将有sentiment的词匹配sentiment
  count(book, index = linenumber %/% 80, sentiment) %>% #对每本书按照index（每80行）对sentiment进行汇总
  spread(key = sentiment, value = n, fill = 0) %>%  #将sentiment的取值变为变量，n变为变量取值，缺失值用0代替
  mutate(sentiment = positive - negative)
js
```

```{r}
ggplot(js, aes(index, sentiment, fill = book)) + 
  geom_col(show.legend = F) + 
  facet_wrap(~ book, ncol = 2, scales = "free_x")
```

```{r}
price_prejudice <- tidy_books %>% 
  filter(book == "Pride & Prejudice")
price_prejudice
```

```{r}
afinn <- price_prejudice %>% 
  inner_join(get_sentiments("afinn"), by = "word") %>% 
  group_by(index = linenumber %/% 80) %>% 
  summarise(sentiment = sum(score)) %>% 
  mutate(method = "AFINN")
afinn
```

```{r}
bing_and_nrc <- bind_rows(
  price_prejudice %>% 
    inner_join(get_sentiments("bing"), by = "word") %>% 
    mutate(method = "BING et al."),
  price_prejudice %>% 
    inner_join(get_sentiments("nrc"), by = "word") %>% 
    filter(sentiment %in% c("positive", "negative")) %>% 
    mutate(method = "NRC")) %>% 
  count(method, index = linenumber %/% 80, sentiment) %>% 
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)
bing_and_nrc
```

```{r}
bind_rows(afinn, bing_and_nrc) %>% 
  ggplot(aes(index, sentiment, fill = method)) + 
  geom_col(show.legend = F) +
  facet_wrap(~ method, ncol = 1, scales = "free_y")
```

```{r}
get_sentiments("nrc") %>% 
  filter(sentiment %in% c("positive", "negative")) %>% 
  count(sentiment)
get_sentiments("bing") %>% 
  count(sentiment)
```

```{r}
bing_word_count <- tidy_books %>% 
  inner_join(get_sentiments("bing"), by = "word") %>% 
  count(word, sentiment, sort = T) %>% 
  ungroup()
bing_word_count
```

```{r}
bing_word_count %>% 
  group_by(sentiment) %>% 
  top_n(10) %>% #输出最高频次项目
  ungroup() %>% 
  mutate(word = reorder(word, n)) %>% 
  ggplot(aes(word, n, fill = sentiment)) + 
  geom_col(show.legend = F) + 
  facet_wrap(~ sentiment, scales = "free_y") + 
  labs(y = "Contribution to sentiment", x = NULL) + 
  coord_flip()
```

```{r}
custom_stop_words <- bind_rows(data.frame(word = c("miss"), lexicon = c("custom")), stop_words) #自定义停用词
custom_stop_words
```

```{r}
tidy_books %>% 
  anti_join(stop_words, by = "word") %>% 
  count(word) %>% 
  with(wordcloud(word = word, freq = n, max.words = 100))
```

```{r}
tidy_books %>% 
  inner_join(get_sentiments("bing"), by = "word") %>% 
  count(word, sentiment, sort = TRUE) %>% 
  acast(word ~ sentiment, value.var = "n", fill = 0) %>% 
  comparison.cloud(colors = c("gray20", "gray80"), max.words = 100)
```
```{r}
PandP_sentences <- data_frame(text = prideprejudice) %>% #生成变量为text的数据框
  unnest_tokens(input = text, output = sentence, token = "sentences") #以句子为单位输出
PandP_sentences
PandP_sentences$sentence[2]
```
```{r}
austen_chapters <- austen_books() %>% 
  group_by(book) %>% 
  unnest_tokens(input = text, output = chapter, token = "regex", #每行对应一章
                pattern = "Chapter|CHAPTER [\\dIVXLC]") %>% 
  ungroup()

austen_chapters %>% 
  group_by(book) %>% 
  summarise(chapters = n())
```
```{r}
bingnegative <- get_sentiments("bing") %>% 
  filter(sentiment == "negative")
bingnegative

wordcounts <- tidy_books %>% 
  group_by(book, chapter) %>% 
  summarize(words = n())
wordcounts

tidy_books %>% 
  semi_join(bingnegative) %>%  #类似inner_join但不会保留bingnegative中的sentiment变量
  group_by(book, chapter) %>% 
  summarise(negativewords = n()) %>% 
  left_join(wordcounts, by = c("book", "chapter")) %>% 
  mutate(ratio = negativewords / words) %>% 
  filter(chapter != 0) %>% 
  top_n(1) %>% #取负面词最多的一章
  ungroup()
```