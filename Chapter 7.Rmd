---
title: "R Notebook"
output: html_notebook
---

#Chapter 7

```{r}
pacman::p_load(lubridate, ggplot2, dplyr, readr)
pacman::p_load(tidytext, stringr)
library(tidyr)
library(scales)
library(purrr)
library(broom)
```

```{r}
tweets_julia <- read_csv("./tidy-text-mining-master/data/tweets_julia.csv")
tweets_dave <- read_csv("./tidy-text-mining-master/data/tweets_dave.csv")
tweets_julia
tweets_dave
tweets <- bind_rows(
  tweets_julia %>% mutate(person = "Julia"),
  tweets_dave %>% mutate(person = "David")
) %>% 
  mutate(timestamp = ymd_hms(timestamp))
tweets
```
```{r}
ggplot(tweets, aes(timestamp, fill = person)) +
  geom_histogram(bins = 20, show.legend = F) +
  facet_wrap(~ person, ncol = 1)
```
```{r}
replace_reg1 <- "https://t.co/[A-Za-z\\d]+|"
replace_reg2 <- "http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https"
replace_reg <- paste0(replace_reg1, replace_reg2)
unnest_reg <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"
tidy_tweets <- tweets %>% 
  filter(!str_detect(text, "^RT")) %>% 
  mutate(text = str_replace_all(text, replace_reg, "")) %>% 
  unnest_tokens(input = text, output = word, token = "regex", pattern = unnest_reg) %>% 
  filter(!word %in% stop_words$word, str_detect(word, "[a-z]"))
tidy_tweets
```
```{r}
frequency <- tidy_tweets %>% 
  group_by(person) %>% 
  count(word, sort = T) %>% 
  left_join(tidy_tweets %>% 
              group_by(person) %>% 
              summarise(total = n())) %>% 
  mutate(freq = n / total)
frequency
```
```{r}
frequency <- frequency %>% 
  select(person, word, freq) %>% 
  spread(key = person, value = freq) %>% 
  arrange(Julia, David)
frequency
```
```{r fig.width=10, fig.height=8}
ggplot(frequency, aes(Julia, David)) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
  geom_text(aes(label = word), check_overlap = T, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) + #scalesåŒ…
  scale_y_log10(labels = percent_format()) +
  geom_abline(color = "red")
```
```{r}
tidy_tweets <- tidy_tweets %>% 
  filter(timestamp >= as.Date("2016-01-01"), timestamp < as.Date("2017-01-01"))
tidy_tweets
```
```{r}
word_ratios <- tidy_tweets %>% 
  filter(!str_detect(word, "^@")) %>% 
  count(word, person) %>% 
  filter(n >= 10) %>% 
  ungroup() %>% 
  spread(key = person, value = n, fill = 0) %>% 
  mutate_if(is.numeric, funs((. + 1) / sum(. + 1))) %>% 
  mutate(logratio = log(David / Julia)) %>% 
  arrange(-logratio)
word_ratios
```
```{r}
word_ratios %>% 
  arrange(abs(logratio))
```
```{r fig.height=8}
word_ratios %>% 
  group_by(logratio < 0) %>% 
  top_n(n = 15, abs(logratio)) %>% 
  ungroup() %>% 
  ggplot(aes(reorder(word, logratio), logratio, fill = logratio < 0)) +
  geom_col(show.legend = F) +
  labs(x = "Terms", y = "Log odds ratio (David / Julia)") +
  coord_flip()
```
```{r}
words_by_time <- tidy_tweets %>% 
  filter(!str_detect(word, "^@")) %>% 
  mutate(time_floor = floor_date(timestamp, unit = "1 month")) %>% 
  count(time_floor, person, word) %>% 
  ungroup() %>% 
  group_by(person, time_floor) %>% 
  mutate(time_total = sum(n)) %>% 
  group_by(word) %>% 
  mutate(word_total = sum(n)) %>% 
  ungroup() %>% 
  rename(count = n) %>% 
  filter(word_total > 30)
words_by_time
```
```{r}
nested_data <- words_by_time %>% 
  nest(-word, -person)
nested_data
```
```{r}
nested_model <- nested_data %>% 
  mutate(models = map(data, ~glm(cbind(count, time_total) ~ time_floor, ., family = "binomial")))
nested_model
```
```{r}
slopes <- nested_model %>% 
  unnest(map(models, tidy)) %>% 
  filter(term == "time_floor") %>% 
  mutate(adjusted.p.value = p.adjust(p.value))
slopes
```
```{r}
top_slopes <- slopes %>% 
  filter(adjusted.p.value < 0.1) %>% 
  select(-statistic, -p.value)
top_slopes
```


```{r}
words_by_time %>% 
  inner_join(top_slopes, by = c("word", "person")) %>% 
  filter(person == "David") %>% 
  ggplot(aes(time_floor, count / time_total, color = word, lty = word)) +
  geom_line(size = 1.3) +
  labs(x = NULL, y = "Word frequency")
```
```{r}
words_by_time %>% 
  inner_join(top_slopes, by = c("word", "person")) %>% 
  filter(person == "Julia") %>% 
  ggplot(aes(time_floor, count / time_total, color = word, lty = word)) +
  geom_line(size = 1.3) +
  labs(x = NULL, y = "Word frequency")
```
```{r}
tweets_julia <- read_csv("./tidy-text-mining-master/data/juliasilge_tweets.csv")
tweets_dave <- read_csv("./tidy-text-mining-master/data/drob_tweets.csv")
tweets <- bind_rows(tweets_julia %>% 
                      mutate(person = "Julia"),
                    tweets_dave %>% 
                      mutate(person = "David")) %>% 
  mutate(created_at = ymd_hms(created_at))
tweets
```
```{r}
tidy_tweets <- tweets %>% 
  select(-source) %>% 
  filter(!str_detect(text, "(RT|@)")) %>% 
  mutate(text = str_replace_all(text, replace_reg, "")) %>% 
  unnest_tokens(input = text, output = word, token = "regex", pattern = unnest_reg) %>% 
  anti_join(stop_words)
tidy_tweets
```
```{r}
totals <- tidy_tweets %>% 
  group_by(person, id) %>% 
  summarise(rts = sum(retweets)) %>% 
  group_by(person) %>% 
  summarise(total_rts = sum(rts))
totals
```
```{r}
word_by_rts <- tidy_tweets %>% 
  group_by(id, word, person) %>% 
  summarise(rts = first(retweets)) %>% 
  group_by(person, word) %>% 
  summarise(retweets = median(rts), uses = n()) %>% 
  left_join(totals) %>% 
  filter(retweets != 0) %>% 
  ungroup()
word_by_rts %>% 
  filter(uses >= 5) %>% 
  arrange(-retweets)
```
```{r}
word_by_rts %>% 
  filter(uses >= 5) %>% 
  group_by(person) %>% 
  top_n(n = 10, wt = retweets) %>% 
  arrange(retweets) %>% 
  ungroup() %>% 
  mutate(word = factor(word, unique(word))) %>% 
  ungroup() %>% 
  ggplot(aes(word, retweets, fill = person)) +
  geom_col(show.legend = F) +
  labs(x = NULL, y = "Median # of retweets for tweets") +
  facet_wrap(~ person, ncol = 2, scales = "free") +
  coord_flip()
```
```{r}
totals <- tidy_tweets %>% 
  group_by(person, id) %>% 
  summarise(favs = sum(favorites)) %>% 
  group_by(person) %>% 
  summarise(total_favs = sum(favs))
word_by_favs <- tidy_tweets %>% 
  group_by(id, word, person) %>% 
  summarise(favs = first(favorites)) %>% 
  group_by(person, word) %>% 
  summarise(favorites = median(favs), uses = n()) %>% 
  left_join(totals) %>% 
  filter(favorites != 0) %>% 
  ungroup()
word_by_favs
```
```{r}
word_by_favs %>% 
  filter(uses >= 5) %>% 
  group_by(person) %>% 
  top_n(n = 10, wt = favorites) %>% 
  arrange(favorites) %>% 
  ungroup() %>% 
  mutate(word = factor(word, unique(word))) %>% 
  ungroup() %>% 
  ggplot(aes(word, favorites, fill = person)) +
  geom_col(show.legend = F) +
  labs(x = NULL, y = "Median # of favorites for tweets") +
  facet_wrap(~ person, ncol = 2, scales = "free") +
  coord_flip()
```

