---
title: "R Notebook"
output: html_notebook
---

#Chapter 8

```{r}
pacman::p_load(jsonlite)
library(dplyr)
library(tidyr)
library(tidytext)
library(widyr)
pacman::p_load(ggplot2, igraph, ggraph)
library(topicmodels)
```

```{r}
metadata <- fromJSON("https://data.nasa.gov/data.json")
names(metadata)
metadata
```

```{r}
nasa_keyword <- data_frame(id = metadata$dataset$identifier,
                           keyword = metadata$dataset$keyword) %>% 
  unnest(keyword)
nasa_keyword
```

```{r}
nasa_title <- data_frame(id = metadata$dataset$identifier,
                         title = metadata$dataset$title) %>% 
  unnest_tokens(input = title, output = word) %>% 
  anti_join(stop_words, by = "word")
nasa_title
```
```{r}
nasa_title %>% 
  count(word, sort = T)
```
```{r}
nasa_desc <- data_frame(id = metadata$dataset$identifier,
                        desc = metadata$dataset$description) %>% 
  unnest_tokens(input = desc, output = word) %>% 
  anti_join(stop_words, by = "word") 
nasa_desc %>% 
  count(word, sort = T)
```
```{r}
my_stopwords <- data_frame(word = c(as.character(1:10),
                                    "v1", "v03", "l2", "l3", "l4", "v5.2.0", "v1.0",
                                    "v003", "v004", "v005", "v005", "v7", "ii"))
nasa_title <- nasa_title %>% 
  anti_join(my_stopwords, by = "word")
nasa_desc <- nasa_desc %>% 
  anti_join(my_stopwords, by = "word")
```

```{r}
nasa_keyword %>% 
  group_by(keyword) %>% 
  count(sort = T)
```
```{r}
nasa_keyword <- nasa_keyword %>% 
  mutate(keyword = toupper(keyword))
nasa_keyword
```
```{r}
title_word_pairs <- nasa_title %>% 
  pairwise_count(item = word, feature = id, sort = T, upper = F)
title_word_pairs
```
```{r}
desc_word_pairs <- nasa_desc %>% 
  pairwise_count(item = word, feature = id, sort = T, upper = F)
desc_word_pairs
```
```{r, fig.width=10}
set.seed(1234)
title_word_pairs %>% 
  filter(n > 100) %>% 
  graph_from_data_frame() %>% 
  ggraph(layout = "fr") + 
  geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
  geom_node_point(size = 5) +
  geom_node_text(aes(label = name), repel = T, point.padding = unit(0.2, "lines")) +
  theme_void()
```
```{r, fig.width=10}
set.seed(1234)
desc_word_pairs %>% 
  filter(n >= 1000) %>% 
  graph_from_data_frame() %>% 
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
  geom_node_point(size = 5) +
  geom_node_text(aes(label = name), repel = T, point.padding = unit(0.2, "lines")) +
  theme_void()
```
```{r}
keyword_pairs <- nasa_keyword %>% 
  pairwise_count(item = keyword, feature = id, sort = T, upper = F)
keyword_pairs
```
```{r, fig.width=10}
set.seed(1234)
keyword_pairs %>% 
  filter(n > 100) %>% 
  graph_from_data_frame() %>% 
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "royalblue") +
  geom_node_point(size = 5) +
  geom_node_text(aes(label = name), repel = T, point.padding = unit(0.2, "lines")) +
  theme_void()
```
```{r}
keyword_cors <- nasa_keyword %>% 
  group_by(keyword) %>% 
  filter(n() >= 50) %>%  #没有count的话要用n()
  pairwise_cor(item = keyword, feature = id, sort = T, upper = F)
keyword_cors
```
```{r, fig.width=10}
set.seed(1234)
keyword_cors %>% 
  filter(correlation > 0.6) %>% 
  graph_from_data_frame() %>% 
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = correlation, edge_width = correlation), edge_colour = "royalblue") +
  geom_node_point(size = 5) +
  geom_node_text(aes(label = name), repel = T, point.padding = unit(0.2, "lines")) +
  theme_void()
```
```{r}
desc_tf_idf <- nasa_desc %>% 
  count(id, word, sort = T) %>% 
  bind_tf_idf(document = id, term = word, n = n)
desc_tf_idf %>% 
  arrange(-tf_idf) %>% 
  select(-id)
```
```{r}
desc_tf_idf <- full_join(desc_tf_idf, nasa_keyword, by = "id")
desc_tf_idf
```
```{r}
desc_tf_idf %>% 
  filter(!near(tf, 1)) %>% 
  filter(keyword %in% c("SOLAR ACTIVITY", "CLOUDS", "SEISMOLOGY", "ASTROPHYSICS", "HUMAN HEALTH", "BUDGET")) %>% 
  arrange(-tf_idf) %>% 
  group_by(keyword) %>% 
  distinct(word, keyword, .keep_all = T) %>% 
  top_n(n = 15, wt = tf_idf) %>% 
  ungroup() %>% 
  ggplot(aes(reorder(word, tf_idf), tf_idf, fill = keyword)) +
  geom_col(show.legend = F) +
  facet_wrap(~ keyword, ncol = 3, scales = "free") +
  labs(title = "Highest tf-idf words",
       caption = "NASA metadata from https://data.nasa.gov/data.json",
       x = NULL,
       y = "tf-idf") +
  coord_flip()
```
```{r}
my_stop_word <- 
  bind_rows(stop_words,
            data_frame(word = c("nbsp", "amp", "gt", "lt",
                                               "timesnewromanpsmt", "font",
                                               "td", "li", "br", "tr", "quot",
                                               "st", "img", "src", "strong",
                                               "http", "file", "files",
                                               as.character(1:12)), 
                                      lexicon = rep("custom", 30)))
word_counts <- nasa_desc %>% 
  anti_join(my_stop_word) %>% 
  count(id, word, sort = T) %>% 
  ungroup()
word_counts
```
```{r}
desc_dtm <- word_counts %>% 
  cast_dtm(document = id, term = word, value = n)
desc_dtm
```
```{r}
desc_lda <- LDA(desc_dtm, k = 24, control = list(seed = 1234))
desc_lda
```
```{r}
class(desc_lda)
tidy_lda <- tidy(desc_lda, matrix = "beta")
tidy_lda
```

